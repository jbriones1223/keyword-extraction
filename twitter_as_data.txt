The increasing prevalence of digital communications technology – the internet and mobile phones – provides the possibility of analyzing human behavior at a level of detail previously unimaginable. Blogs, content aggregation sites, internet fora, online social networks, and call data records provide access to data that vary by the second. For political scientists interested in questions about elections, language, political communication, conflict, or spatial diffusion, among others, the rise of these technologies holds much promise (Grimmer and Stewart, 2013; Bail, 2014).
These data require new tools to acquire, process, and, sometimes, analyze. These tools are no more difficult to learn and use than other qualitative and quantitative methods, but they are not commonly taught to social scientists. There also exists no canonical text, in journal or book form, that explains the strengths and weaknesses of these data and tools. This Element provides a systematic introduction to these data sources and the tools needed to benefit from them.
While digital communications technology provides data through numerous platforms, I focus on one, the social network Twitter. With over 300 million accounts creating 500 million messages per day, it is one of the largest social networks. Its data are also relatively easy to access, unlike Facebook’s. While other social media platforms and websites also facilitate data access, none is as general purpose as Twitter. Twitter’s global reach, large user base, and data openness make it the preferred platform for large-scale studies of human behavior.
I use the Twitter behavior of 21 accounts from Egypt and Bahrain as a running example. Nineteen of these accounts belong to civil society actors from four different social movements, and two belong to the Bahraini government. I detail how to purchase their tweets, download their old tweets, download specific tweets based on a unique tweet identifier, download their new tweets as they are created, and analyze these tweets. Analysis will focus on textual and spatial analysis; for an explanation of network analysis using Twitter, see Steinert-Threlkeld (2016). Throughout these examples, I provide full working code as well as any data necessary.
The rest of this Element is divided into a further five sections. Section 2 explains where to acquire Twitter data for your research. You can download the data yourself through the REST API or streaming API (see the glossary for a definition of REST, API, and other acronyms.) The REST API is for finding user metadata, account relationships, and old tweets. The streaming API is for downloading data in real time. You can purchase them, or you can work with a collaborator who has obtained data that matches your research interests.
Section 3 details how to acquire Twitter data from the REST API and streaming API. It starts with creating a Twitter account, which is necessary to access the API. It then provides code for the most common data needs: downloading a user’s tweets, downloading specific tweets, finding tweets, or downloading lists of an account’s followers and the accounts a specific account follows. The section also shows how to connect to the streaming API for a random sample. The streaming API accepts parameters for language, keywords, accounts, and places, and the section shows how to use those as well. It then finishes with a discussion of different data storage approaches.
Section 4 shows how to conduct common analyses on data acquired via the methods in Sections 2 and 3. Processing is required to move from raw tweets to tweets in rectangular format. The section then shows how to conduct text analysis using tweets and detect real-world events from them. It also discusses possibilities of image analysis and generating metadata for a tweet, such as demographic information.
Section 5 discusses how social scientists have used Twitter to date. Only in the last five years have scholars started to incorporate Twitter into quantitative analyses. Work has focused on using Twitter to measure conflict dynamics, social networks, political preferences, legislative responsiveness, economic outcomes, and mobilization for contentious action. The section also discusses social media platforms, such as Facebook and Instagram, and explains why Twitter is likely to remain the dominant source of social network data for social scientists.
Section 6 concludes with several discussions of Twitter as a data source. The section discusses limits to acquiring data and making inferences given the little information provided in individual tweets. It discusses potential ethical concerns with tweets, especially around protected groups of people such as children. Finally, it concludes that Twitter exhibits characteristics of a media platform and social network, meaning social scientists can use it to study both media, elite individuals, and normal people.

Six features of Twitter have driven its popularity for academic study. First, it is one of the largest social networks, with 319 million monthly active users from almost every country and over $1 billion of annual revenue (Twitter, 2016). These users include heads of state, companies, non-profit organizations, international non-governmental organizations, celebrities, athletes, journalists, academics, and, primarily, normal people. In the United States, as of November 2016, 24% of adults use Twitter; men and women use it equally, a plurality of users are between 18 and 29 years of age (a majority, 18–49), a plurality of users have at least a college degree (20% have a high school degree or less), a majority earn more than $50,000 per year, and users are evenly distributed across urban, suburban, and rural areas. Forty-two percent of its users use it daily and 24% at least once a week (versus 76% and 15% for Facebook) (Greenwood et al., 2016). Twitter therefore provides a cross-section of almost any group in which a researcher would find interest.
Second, users produce copious data, 500 million messages per day. All these people and messages mean that Twitter mirrors vast segments of the population that would otherwise require large teams of researchers to analyze concurrently. Taken together, these first two characteristics mean that almost any event is recorded on Twitter, and many events are predictable as a result of it. For literature on event prediction using Twitter, see Table 1 at the end of Section 1.2.
Third, it makes these data relatively easy to obtain. Twitter provides users’ data through two APIs, the streaming API and the REST API, that are accessible to anyone with a Twitter account. Before the switch to v1.1 of the APIs, Twitter allowed third parties to provide interfaces that allowed individuals with no programming experience to access its APIs. Now, that capability no longer exists, raising the barrier to entry for acquiring data. Nonetheless, because of Twitter’s popularity, there are a large number of software libraries to access Twitter, including in Python and R. You need some programming knowledge to interact with the APIs, though not as much as just a few years ago. The primary purpose of this Element is to help the reader gain that knowledge.
Fourth, the APIs make it easy to tailor the data received to a specific research question. You can receive as much as 1% of all tweets every day (from the streaming API) or filter the tweets received based on keywords, user location, user IDs, or language used. Through the REST API, you can download specific tweets, 3,200 of a user’s most recent tweets, a list of who a user follows or who follows the user, and user profile information. In other words, though Twitter has pioneered many “big data” technologies, you do not necessarily need to possess these skills to access Twitter’s data. You may need to learn new skills to gather the data, but modeling and visualizing those data can be done with old tools of the trade.
Fifth, Twitter is an excellent data source for network and non-network analysis. Since the service is explicitly structured as a network – connections between accounts are the fundamental building blocks of the user experience – researchers interested in diffusion processes and emergent behavior find Twitter a natural resource. But Twitter, because its 1% stream delivers tweets without information on the tweet author’s social network, is also a compelling source for researchers interested in polling and event prediction (Gayo-Avello, 2013).
Sixth, Twitter has a norm of public conversation that does not exist on Facebook. While Facebook also provides an API, most users choose not to make their information publicly available. To gain access to a private user’s information, you need to design a Facebook app that the user installs, or work with Facebook’s research team. This team maintains veto power over research proposals and publications, and the recent controversy over manipulation of Facebook feeds has caused Facebook to tighten control over its research team (Kramer et al., 2014).

Twitter data can be used to answer questions that involve three kinds of data: networks, text, and spatial.
Perhaps the most exciting potential of Twitter is as a tool for reconstructing social networks. Networks can be reconstructed from streaming data or data downloaded through the REST API. Because the REST API provides follower and friend information, it permits the reconstruction of all of a user’s connections. A researcher interested in the complete social network of an individual therefore has to use the REST API.
Computationally analyzing text is a growing field in the social sciences (Grimmer and Stewart, 2013; Lucas et al., 2015), and Twitter provides scholars with large corpora. The barriers to entry for appearing in a Twitter sample are substantially lower than for a news report or in Congress. People who are not likely to appear in those sources are therefore much more likely to appear on Twitter, casting light on swathes of previously unobservable behavior. While this outcome is true of the internet more broadly – barriers to entry are similarly low for joining most social networks, posting on web forums, or starting a blog – Twitter is unique in its combination of size and public communication. Elites who are likely to appear in traditional text sources usually have Twitter accounts (every Senator and 430 members of the House have official Twitter accounts, as do most news organizations), meaning Twitter records communication behavior from all strata of society. No other data source exists that is simultaneously comprehensive and accessible. For literature that applies natural language processing to Twitter, see Table 1.
It is also possible to map Twitter activity to specific places, allowing scholars to connect patterns on Twitter to offline events. Location information comes from two sources, accounts choosing to provide their GPS coordinates or self-reporting their location as part of their profile. Tweets with GPS coordinates, which represent 2–3% of all tweets (Leetaru et al., 2013), provide the most precision in estimating location. Tweets with GPS coordinates are more prevalent in urban areas and among higher-income users, so the extent to which they are reliable depends on the research question (Malik et al., 2015). See the Supplementary Materials for an analysis of which countries produce the most tweets with GPS coordinates, both in absolute and per capita terms. See Table 1 for examples of mapping Twitter to events.

Twitter data can be acquired, processed, and analyzed with many programming languages, including R and Python. R is the programming language most familiar to political scientists. An extension of S, a language developed at Bell Laboratories in the 1970s, R was designed by statisticians. While it can perform many general computation functions, its comparative advantage is in statistical analysis. When a new statistical procedure is developed, the first implementation is usually as an R package.
R can ingest Twitter data in three ways. streamR is a package that makes it easy to connect to R’s streaming API and write the returned tweets to a .csv or JSON file (Barberá, 2013). twitteR is designed to work with the REST API, though the complexity of the REST API compared to the streaming one means the package is not as robust as streamR (Gentry, 2015). You could avoid these packages completely by using the RCurl package, which facilitates interaction with the HTTP endpoints that web services, including Twitter, use (Lang et al., 2016). Using RCurl provides the most flexibility but requires more coding than using a package designed to work with Twitter.
Python is a general purpose language tracing its lineage to 1989 and is most famous for having easy to read code. Whereas R was created for data analysis and has been extended to other purposes, Python was created to work with computers and has been extended to data analysis. Transitioning from writing in R to writing in Python for the first time is much easier than transitioning from never having written code to writing in R.
The primary Python library for working with Twitter is twython (McGrath, 2015). (Tweepy is another Python library to access Twitter, but twython has a larger community and is more frequently updated). Unlike any R package, twython can work with Twitter’s REST or streaming API and has built in exception handling. Python’s pandas library provides data frames equivalent to R’s as well as reshaping, merging, and aggregation capabilities spread across multiple R packages (McKinney, 2015); pandas is much faster than base R, though R’s data.table package is as fast or even slightly faster than pandas (Dowle et al., 2015). Python’s statistical libraries are not as deep as R, though most parametric and non-parametric models are available through the statsmodels package (Seabold and Perktold, 2014). Libraries for Bayesian analysis are not as developed, though Stan has a Python interface. Python also has extensive libraries for natural language processing (Bird et al., 2009) and machine learning (Mueller, 2015) if there are statistical domains in which Python strictly dominates R, it is these two.
Neither R nor Python strictly dominates the other. Python has more developed tools for scraping web pages, but Hadley Wickham’s rvest package narrows this gap. Python is generally faster, but new R packages such as data.table erase that difference on some dimensions. R’s syntax does not resemble that of other computer languages, but it is also easy to read and learn. The one area Python dominates R for data analysis is data storage: many more database products have Python libraries than R ones, though R has libraries for working with SQL, SQLLite, and MongoDB (a prominent NoSQL database). That said, most people are unlikely to need a database for their Twitter work. R dominates Python in developing aesthetically pleasing graphics, though a Python port of ggplot is being developed and Python’s matplotlib library produces Matlib style graphics. If you already know R, learning Python may be worthwhile, but the costs and benefits require careful consideration since either language can most likely accomplish your programming task, and human time is the most scarce resource on any project. The more likely you are to work with large amounts of data or colleagues from outside the social sciences, the more beneficial Python knowledge becomes. If you know neither R nor Python, learn both.